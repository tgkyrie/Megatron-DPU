root@server2:/workspace/Megatron-LM# torchrun --nproc_per_node=1 --nnodes=$NNODES --node_rank=$NODE_RANK \
  --master_addr=$MASTER_ADDR --master_port=$MASTER_PORT \
  pretrain_gpt.py \
  --num-layers 12 \
  --hidden-size 768 \
  --num-attention-heads 12 \
  --micro-batch-size 8 \
  --global-batch-size 16 \
  --seq-length 512 \
  --vocab-size 50257 \
  --tensor-model-parallel-size 1 \
  --pipeline-model-parallel-size 1 \
  --mock_data \
  --log-interval 10
/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/models/backends.py:21: UserWarning: Apex is not installed. Falling back to Torch Norm
  warnings.warn("Apex is not installed. Falling back to Torch Norm")
/workspace/Megatron-LM/megatron/training/utils.py:23: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier and multi_tensor_l2norm
  warnings.warn(
fused_indices_to_multihot has reached end of life. Please migrate to a non-experimental function.
/workspace/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:67: UserWarning: Apex is not installed. Falling back to Torch Norm
  warnings.warn("Apex is not installed. Falling back to Torch Norm")
/workspace/Megatron-LM/megatron/core/models/retro/encoder_spec.py:49: UserWarning: Apex is not installed. Falling back to Torch Norm
  warnings.warn(f'Apex is not installed. Falling back to Torch Norm')
/workspace/Megatron-LM/megatron/core/models/retro/decoder_spec.py:39: UserWarning: Apex is not installed. Falling back to Torch Norm
  warnings.warn(f"Apex is not installed. Falling back to Torch Norm")
/workspace/Megatron-LM/megatron/core/optimizer/__init__.py:22: UserWarning: Transformer Engine and Apex are not installed. Falling back to Torch optimizers.
  warnings.warn(
/workspace/Megatron-LM/megatron/core/optimizer/optimizer.py:27: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier and multi_tensor_scale
  warnings.warn(
/workspace/Megatron-LM/megatron/core/optimizer/clip_grads.py:29: UserWarning: Transformer Engine and Apex are not installed. Falling back to local implementations of multi_tensor_applier, multi_tensor_l2norm, and multi_tensor_scale
  warnings.warn(
/workspace/Megatron-LM/megatron/core/models/gpt/heterogeneous/heterogeneous_layer_specs.py:63: UserWarning: Apex is not installed. Falling back to Torch Norm
  warnings.warn("Apex is not installed. Falling back to Torch Norm")
usage: pretrain_gpt.py [-h] [--num-layers NUM_LAYERS] [--encoder-num-layers ENCODER_NUM_LAYERS]
                       [--decoder-num-layers DECODER_NUM_LAYERS] [--hidden-size HIDDEN_SIZE]
                       [--ffn-hidden-size FFN_HIDDEN_SIZE] [--num-attention-heads NUM_ATTENTION_HEADS]
                       [--attention-backend {AttnBackend.flash,AttnBackend.fused,AttnBackend.unfused,AttnBackend.local,AttnBackend.auto}]
                       [--kv-channels KV_CHANNELS] [--group-query-attention] [--num-query-groups NUM_QUERY_GROUPS]
                       [--softmax-type {learnable,vanilla,off-by-one}] [--window-size WINDOW_SIZE]
                       [--window-attn-skip-freq WINDOW_ATTN_SKIP_FREQ]
                       [--max-position-embeddings MAX_POSITION_EMBEDDINGS]
                       [--position-embedding-type {learned_absolute,rope,mrope,relative,none}]
                       [--relative-attention-num-buckets RELATIVE_ATTENTION_NUM_BUCKETS]
                       [--relative-attention-max-distance RELATIVE_ATTENTION_MAX_DISTANCE]
                       [--use-rotary-position-embeddings] [--rotary-base ROTARY_BASE]
                       [--rotary-percent ROTARY_PERCENT] [--rotary-interleaved]
                       [--rotary-seq-len-interpolation-factor ROTARY_SEQ_LEN_INTERPOLATION_FACTOR]
                       [--use-rope-scaling] [--rope-scaling-factor ROPE_SCALING_FACTOR] [--no-rope-freq NO_ROPE_FREQ]
                       [--no-position-embedding] [--mrope-section MROPE_SECTION [MROPE_SECTION ...]]
                       [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]
                       [--normalization {LayerNorm,RMSNorm}] [--norm-epsilon NORM_EPSILON] [--apply-layernorm-1p]
                       [--apply-residual-connection-post-layernorm] [--openai-gelu] [--squared-relu] [--swiglu]
                       [--quick-geglu] [--activation-func-clamp-value ACTIVATION_FUNC_CLAMP_VALUE]
                       [--glu-linear-offset GLU_LINEAR_OFFSET] [--onnx-safe ONNX_SAFE] [--bert-no-binary-head]
                       [--untie-embeddings-and-output-weights] [--multi-latent-attention]
                       [--mtp-num-layers MTP_NUM_LAYERS] [--mtp-loss-scaling-factor MTP_LOSS_SCALING_FACTOR]
                       [--attention-dropout ATTENTION_DROPOUT] [--hidden-dropout HIDDEN_DROPOUT]
                       [--weight-decay WEIGHT_DECAY] [--start-weight-decay START_WEIGHT_DECAY]
                       [--end-weight-decay END_WEIGHT_DECAY] [--weight-decay-incr-style {constant,linear,cosine}]
                       [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1] [--adam-beta2 ADAM_BETA2]
                       [--adam-eps ADAM_EPS] [--sgd-momentum SGD_MOMENTUM] [--micro-batch-size MICRO_BATCH_SIZE]
                       [--batch-size BATCH_SIZE] [--global-batch-size GLOBAL_BATCH_SIZE]
                       [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]] [--decrease-batch-size-if-needed]
                       [--recompute-activations] [--recompute-granularity {full,selective}]
                       [--no-check-for-nan-in-loss-and-grad] [--check-for-spiky-loss] [--check-for-large-grads]
                       [--distribute-saved-activations] [--recompute-method {uniform,block}]
                       [--recompute-num-layers RECOMPUTE_NUM_LAYERS] [--recompute-modules [RECOMPUTE_MODULES ...]]
                       [--no-clone-scatter-output-in-embedding] [--profile] [--profile-step-start PROFILE_STEP_START]
                       [--profile-step-end PROFILE_STEP_END]
                       [--iterations-to-skip ITERATIONS_TO_SKIP [ITERATIONS_TO_SKIP ...]]
                       [--result-rejected-tracker-filename RESULT_REJECTED_TRACKER_FILENAME]
                       [--disable-gloo-process-groups] [--use-pytorch-profiler]
                       [--profile-ranks PROFILE_RANKS [PROFILE_RANKS ...]] [--record-memory-history]
                       [--memory-snapshot-path MEMORY_SNAPSHOT_PATH] [--tp-comm-overlap]
                       [--tp-comm-overlap-cfg TP_COMM_OVERLAP_CFG] [--disable-tp-comm-overlap-ag]
                       [--disable-tp-comm-overlap-rs] [--tp-comm-overlap-rs-dgrad] [--disable-tp-comm-bulk-dgrad]
                       [--disable-tp-comm-bulk-wgrad] [--tp-comm-bootstrap-backend {nccl,mpi,gloo}]
                       [--use-cpu-initialization] [--empty-unused-memory-level {0,1,2}] [--deterministic-mode]
                       [--check-weight-hash-across-dp-replicas-interval CHECK_WEIGHT_HASH_ACROSS_DP_REPLICAS_INTERVAL]
                       [--calculate-per-token-loss] [--train-sync-interval TRAIN_SYNC_INTERVAL]
                       [--checkpoint-activations] [--train-iters TRAIN_ITERS] [--train-samples TRAIN_SAMPLES]
                       [--log-interval LOG_INTERVAL] [--exit-interval EXIT_INTERVAL]
                       [--exit-duration-in-mins EXIT_DURATION_IN_MINS] [--exit-signal-handler]
                       [--tensorboard-dir TENSORBOARD_DIR] [--no-masked-softmax-fusion] [--no-bias-gelu-fusion]
                       [--no-bias-swiglu-fusion] [--use-fused-weighted-squared-relu] [--no-bias-dropout-fusion]
                       [--no-rope-fusion] [--rope-type {rope,yarn}] [--cross-entropy-loss-fusion]
                       [--cross-entropy-fusion-impl {native,te}] [--use-flash-attn] [--disable-bias-linear]
                       [--add-qkv-bias] [--optimizer {adam,sgd}] [--optimizer-cpu-offload]
                       [--optimizer-offload-fraction OPTIMIZER_OFFLOAD_FRACTION]
                       [--use-torch-optimizer-for-cpu-offload] [--overlap-cpu-optimizer-d2h-h2d] [--no-pin-cpu-grads]
                       [--no-pin-cpu-params] [--dataloader-type {single,cyclic,external}]
                       [--no-async-tensor-model-parallel-allreduce] [--no-persist-layer-norm] [--sequence-parallel]
                       [--no-gradient-accumulation-fusion] [--use-mcore-models] [--use-legacy-models] [--manual-gc]
                       [--manual-gc-interval MANUAL_GC_INTERVAL] [--no-manual-gc-eval] [--disable-tp-comm-split-ag]
                       [--disable-tp-comm-split-rs] [--pipeline-model-parallel-comm-backend {nccl,ucc}]
                       [--high-priority-stream-groups [HIGH_PRIORITY_STREAM_GROUPS ...]] [--use-te-activation-func]
                       [--perform-rl-step] [--rl-prompts-per-eval RL_PROMPTS_PER_EVAL]
                       [--grpo-prompts-per-step GRPO_PROMPTS_PER_STEP] [--grpo-group-size GRPO_GROUP_SIZE]
                       [--grpo-iterations GRPO_ITERATIONS] [--grpo-clamp-eps-lower GRPO_CLAMP_EPS_LOWER]
                       [--grpo-clamp-eps-upper GRPO_CLAMP_EPS_UPPER] [--grpo-kl-beta GRPO_KL_BETA]
                       [--grpo-entropy-term-weight GRPO_ENTROPY_TERM_WEIGHT] [--grpo-filter-groups-with-same-reward]
                       [--grpo-default-temperature GRPO_DEFAULT_TEMPERATURE] [--grpo-default-top-p GRPO_DEFAULT_TOP_P]
                       [--langrl-inference-server-type {inplace_megatron,inplace_megatron_chat}]
                       [--langrl-inference-server-conversation-template LANGRL_INFERENCE_SERVER_CONVERSATION_TEMPLATE]
                       [--langrl-env-config LANGRL_ENV_CONFIG] [--rl-offload-optimizer-during-inference]
                       [--rl-offload-kv-cache-during-training | --no-rl-offload-kv-cache-during-training]
                       [--rl-remove-kv-cache-during-training | --no-rl-remove-kv-cache-during-training]
                       [--rl-reset-cuda-graphs | --no-rl-reset-cuda-graphs]
                       [--rl-partial-rollouts | --no-rl-partial-rollouts]
                       [--rl-inference-logprobs-is-correction | --no-rl-inference-logprobs-is-correction]
                       [--rl-importance-sampling-truncation-coef RL_IMPORTANCE_SAMPLING_TRUNCATION_COEF]
                       [--rl-calculate-intra-group-similarity | --no-rl-calculate-intra-group-similarity]
                       [--seed SEED] [--data-parallel-random-init] [--init-method-std INIT_METHOD_STD]
                       [--embedding-init-method-std EMBEDDING_INIT_METHOD_STD] [--init-method-xavier-uniform]
                       [--lr LR] [--lr-decay-style {constant,linear,cosine,inverse-square-root,WSD}]
                       [--lr-wsd-decay-style {exponential,linear,cosine,minus_sqrt}] [--lr-decay-iters LR_DECAY_ITERS]
                       [--lr-decay-samples LR_DECAY_SAMPLES] [--lr-wsd-decay-samples LR_WSD_DECAY_SAMPLES]
                       [--lr-wsd-decay-iters LR_WSD_DECAY_ITERS] [--lr-warmup-fraction LR_WARMUP_FRACTION]
                       [--lr-warmup-iters LR_WARMUP_ITERS] [--lr-warmup-samples LR_WARMUP_SAMPLES]
                       [--lr-warmup-init LR_WARMUP_INIT] [--warmup WARMUP] [--min-lr MIN_LR]
                       [--override-opt_param-scheduler] [--use-checkpoint-opt_param-scheduler]
                       [--decoupled-lr DECOUPLED_LR] [--decoupled-min-lr DECOUPLED_MIN_LR] [--save SAVE]
                       [--save-interval SAVE_INTERVAL] [--save-retain-interval SAVE_RETAIN_INTERVAL] [--no-save-optim]
                       [--no-save-rng] [--load LOAD] [--no-load-optim] [--load-main-params-from-ckpt] [--no-load-rng]
                       [--no-strict-fsdp-dtensor-load] [--non-persistent-save-interval NON_PERSISTENT_SAVE_INTERVAL]
                       [--non-persistent-ckpt-type {global,local,in_memory,None}]
                       [--non-persistent-global-ckpt-dir NON_PERSISTENT_GLOBAL_CKPT_DIR]
                       [--non-persistent-local-ckpt-dir NON_PERSISTENT_LOCAL_CKPT_DIR]
                       [--non-persistent-local-ckpt-algo {fully_parallel,atomic}] [--finetune]
                       [--pretrained-checkpoint PRETRAINED_CHECKPOINT] [--ckpt-step CKPT_STEP] [--no-initialization]
                       [--use-checkpoint-args] [--use-mp-args-from-checkpoint-args]
                       [--no-use-tokenizer-model-from-checkpoint-args] [--exit-on-missing-checkpoint]
                       [--use-dist-ckpt] [--use-persistent-ckpt-worker] [--auto-detect-ckpt-format]
                       [--dist-ckpt-format DIST_CKPT_FORMAT_DEPRECATED]
                       [--ckpt-format {torch,torch_dist,zarr,torch_dcp,fsdp_dtensor}]
                       [--ckpt-convert-format {torch,torch_dist,zarr}] [--ckpt-convert-save CKPT_CONVERT_SAVE]
                       [--ckpt-convert-update-legacy-dist-opt-format] [--ckpt-fully-parallel-save]
                       [--no-ckpt-fully-parallel-save] [--async-save] [--ckpt-fully-parallel-load]
                       [--ckpt-assume-constant-structure]
                       [--dist-ckpt-strictness {assume_ok_unexpected,log_unexpected,log_all,raise_unexpected,raise_all,return_unexpected,return_all,ignore_all}]
                       [--dist-ckpt-save-pre-mcore-014] [--dist-ckpt-optim-fully-reshardable]
                       [--distrib-optim-fully-reshardable-mem-efficient] [--load-model-opt-format] [--fp16] [--bf16]
                       [--grad-reduce-in-bf16] [--loss-scale LOSS_SCALE] [--initial-loss-scale INITIAL_LOSS_SCALE]
                       [--min-loss-scale MIN_LOSS_SCALE] [--loss-scale-window LOSS_SCALE_WINDOW]
                       [--hysteresis HYSTERESIS] [--fp32-residual-connection] [--apply-query-key-layer-scaling]
                       [--attention-softmax-in-fp32] [--accumulate-allreduce-grads-in-fp32] [--fp16-lm-cross-entropy]
                       [--disable-bf16-reduced-precision-matmul] [--reuse-grad-buf-for-mxfp8-param-ag]
                       [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]
                       [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]
                       [--decoder-first-pipeline-num-layers DECODER_FIRST_PIPELINE_NUM_LAYERS]
                       [--decoder-last-pipeline-num-layers DECODER_LAST_PIPELINE_NUM_LAYERS]
                       [--pipeline-model-parallel-layout PIPELINE_MODEL_PARALLEL_LAYOUT]
                       [--model-parallel-size MODEL_PARALLEL_SIZE]
                       [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]
                       [--num-virtual-stages-per-pipeline-rank NUM_VIRTUAL_STAGES_PER_PIPELINE_RANK]
                       [--microbatch-group-size-per-virtual-pipeline-stage MICROBATCH_GROUP_SIZE_PER_VP_STAGE]
                       [--no-overlap-p2p-communication] [--overlap-p2p-communication-warmup-flush]
                       [--distributed-backend {nccl,gloo}] [--distributed-timeout-minutes DISTRIBUTED_TIMEOUT_MINUTES]
                       [--distributed-timeout-seconds-after-init DISTRIBUTED_TIMEOUT_SECONDS_AFTER_INIT]
                       [--overlap-grad-reduce] [--defer-embedding-wgrad-compute]
                       [--wgrad-deferral-limit WGRAD_DEFERRAL_LIMIT] [--no-align-grad-reduce]
                       [--ddp-num-buckets DDP_NUM_BUCKETS] [--ddp-bucket-size DDP_BUCKET_SIZE]
                       [--ddp-pad-buckets-for-high-nccl-busbw] [--ddp-average-in-collective] [--overlap-param-gather]
                       [--overlap-param-gather-with-optimizer-step] [--no-align-param-gather]
                       [--no-scatter-gather-tensors-in-pipeline] [--use-ring-exchange-p2p] [--local-rank LOCAL_RANK]
                       [--lazy-mpu-init LAZY_MPU_INIT] [--account-for-embedding-in-pipeline-split]
                       [--account-for-loss-in-pipeline-split] [--use-distributed-optimizer] [--use-nccl-ub]
                       [--disable-symmetric-registration] [--use-sharp] [--sharp-enabled-group {dp,dp_replica}]
                       [--use-megatron-fsdp] [--init-model-with-meta-device]
                       [--data-parallel-sharding-strategy {no_shard,optim,optim_grads,optim_grads_params}]
                       [--no-gradient-reduce-div-fusion] [--fsdp-double-buffer]
                       [--suggested-communication-unit-size SUGGESTED_COMMUNICATION_UNIT_SIZE]
                       [--keep-fp8-transpose-cache] [--enable-full-sharding-in-hsdp]
                       [--num-distributed-optimizer-instances NUM_DISTRIBUTED_OPTIMIZER_INSTANCES] [--use-torch-fsdp2]
                       [--torch-fsdp2-no-reshard-after-forward] [--context-parallel-size CONTEXT_PARALLEL_SIZE]
                       [--cp-comm-type CP_COMM_TYPE [CP_COMM_TYPE ...]]
                       [--hierarchical-context-parallel-sizes HIERARCHICAL_CONTEXT_PARALLEL_SIZES [HIERARCHICAL_CONTEXT_PARALLEL_SIZES ...]]
                       [--nccl-communicator-config-path NCCL_COMMUNICATOR_CONFIG_PATH] [--use-tp-pp-dp-mapping]
                       [--replication] [--replication-jump REPLICATION_JUMP] [--replication-factor REPLICATION_FACTOR]
                       [--full-validation] [--multiple-validation-sets] [--eval-iters EVAL_ITERS]
                       [--eval-interval EVAL_INTERVAL] [--test-mode] [--skip-train] [--data-path [DATA_PATH ...]]
                       [--split SPLIT] [--train-data-path [TRAIN_DATA_PATH ...]]
                       [--valid-data-path [VALID_DATA_PATH ...]] [--test-data-path [TEST_DATA_PATH ...]]
                       [--data-args-path DATA_ARGS_PATH] [--per-split-data-args-path PER_SPLIT_DATA_ARGS_PATH]
                       [--data-cache-path DATA_CACHE_PATH] [--no-mmap-bin-files] [--mock-data]
                       [--seq-length SEQ_LENGTH] [--encoder-seq-length ENCODER_SEQ_LENGTH]
                       [--decoder-seq-length DECODER_SEQ_LENGTH] [--retriever-seq-length RETRIEVER_SEQ_LENGTH]
                       [--sample-rate SAMPLE_RATE] [--mask-prob MASK_PROB] [--short-seq-prob SHORT_SEQ_PROB]
                       [--num-workers NUM_WORKERS] [--reset-position-ids] [--reset-attention-mask] [--eod-mask-loss]
                       [--no-create-attention-mask-in-dataloader]
                       [--num-dataset-builder-threads NUM_DATASET_BUILDER_THREADS]
                       [--object-storage-cache-path OBJECT_STORAGE_CACHE_PATH]
                       [--mid-level-dataset-surplus MID_LEVEL_DATASET_SURPLUS] [--vocab-size VOCAB_SIZE]
                       [--padded-vocab-size PADDED_VOCAB_SIZE] [--vocab-file VOCAB_FILE] [--merge-file MERGE_FILE]
                       [--vocab-extra-ids VOCAB_EXTRA_IDS]
                       [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer,SentencePieceTokenizer,GPTSentencePieceTokenizer,HuggingFaceTokenizer,Llama2Tokenizer,TikTokenizer,MultimodalTokenizer,NullTokenizer,NullMultimodalTokenizer,SFTTokenizer}]
                       [--tokenizer-model TOKENIZER_MODEL] [--tokenizer-metadata TOKENIZER_METADATA]
                       [--tiktoken-pattern TIKTOKEN_PATTERN]
                       [--tiktoken-num-special-tokens TIKTOKEN_NUM_SPECIAL_TOKENS]
                       [--tiktoken-special-tokens TIKTOKEN_SPECIAL_TOKENS [TIKTOKEN_SPECIAL_TOKENS ...]]
                       [--legacy-tokenizer] [--trust-remote-code] [--adlr-autoresume]
                       [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL] [--ict-head-size ICT_HEAD_SIZE]
                       [--biencoder-projection-dim BIENCODER_PROJECTION_DIM] [--biencoder-shared-query-context-model]
                       [--ict-load ICT_LOAD] [--bert-load BERT_LOAD] [--titles-data-path TITLES_DATA_PATH]
                       [--query-in-block-prob QUERY_IN_BLOCK_PROB] [--use-one-sent-docs]
                       [--evidence-data-path EVIDENCE_DATA_PATH]
                       [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]
                       [--retriever-score-scaling] [--block-data-path BLOCK_DATA_PATH]
                       [--embedding-path EMBEDDING_PATH] [--indexer-batch-size INDEXER_BATCH_SIZE]
                       [--indexer-log-interval INDEXER_LOG_INTERVAL] [--num-classes NUM_CLASSES] [--img-h IMG_H]
                       [--img-w IMG_W] [--num-channels NUM_CHANNELS] [--patch-dim PATCH_DIM]
                       [--classes-fraction CLASSES_FRACTION] [--data-per-class-fraction DATA_PER_CLASS_FRACTION]
                       [--no-data-sharding] [--head-lr-mult HEAD_LR_MULT] [--vision-pretraining]
                       [--vision-pretraining-type {classify,inpaint,dino}] [--vision-backbone-type {vit,mit,swin}]
                       [--swin-backbone-type {tiny,base,h3}] [--mask-type {random,row}] [--mask-factor MASK_FACTOR]
                       [--iter-per-epoch ITER_PER_EPOCH] [--dino-local-img-size DINO_LOCAL_IMG_SIZE]
                       [--dino-local-crops-number DINO_LOCAL_CROPS_NUMBER]
                       [--dino-head-hidden-size DINO_HEAD_HIDDEN_SIZE] [--dino-bottleneck-size DINO_BOTTLENECK_SIZE]
                       [--dino-freeze-last-layer DINO_FREEZE_LAST_LAYER] [--dino-norm-last-layer]
                       [--dino-warmup-teacher-temp DINO_WARMUP_TEACHER_TEMP] [--dino-teacher-temp DINO_TEACHER_TEMP]
                       [--dino-warmup-teacher-temp-epochs DINO_WARMUP_TEACHER_TEMP_EPOCHS] [--qk-layernorm]
                       [--qk-l2-norm] [--expert-model-parallel-size EXPERT_MODEL_PARALLEL_SIZE]
                       [--expert-tensor-parallel-size EXPERT_TENSOR_PARALLEL_SIZE] [--num-experts NUM_EXPERTS]
                       [--moe-layer-freq MOE_LAYER_FREQ] [--moe-ffn-hidden-size MOE_FFN_HIDDEN_SIZE]
                       [--moe-shared-expert-intermediate-size MOE_SHARED_EXPERT_INTERMEDIATE_SIZE]
                       [--moe-shared-expert-overlap] [--moe-grouped-gemm] [--moe-use-legacy-grouped-gemm]
                       [--moe-layer-recompute] [--moe-extended-tp] [--moe-use-upcycling]
                       [--moe-router-load-balancing-type {aux_loss,seq_aux_loss,global_aux_loss,sinkhorn,none} [{aux_loss,seq_aux_loss,global_aux_loss,sinkhorn,none} ...]]
                       [--moe-router-dtype {fp32,fp64}] [--moe-router-fusion]
                       [--moe-router-score-function {softmax,sigmoid}] [--moe-router-topk MOE_ROUTER_TOPK]
                       [--moe-router-pre-softmax] [--moe-router-num-groups MOE_ROUTER_NUM_GROUPS]
                       [--moe-router-group-topk MOE_ROUTER_GROUP_TOPK]
                       [--moe-router-topk-scaling-factor MOE_ROUTER_TOPK_SCALING_FACTOR]
                       [--moe-router-enable-expert-bias] [--moe-router-bias-update-rate MOE_ROUTER_BIAS_UPDATE_RATE]
                       [--moe-router-force-load-balancing] [--moe-router-padding-for-fp8]
                       [--moe-aux-loss-coeff MOE_AUX_LOSS_COEFF [MOE_AUX_LOSS_COEFF ...]]
                       [--moe-z-loss-coeff MOE_Z_LOSS_COEFF] [--moe-input-jitter-eps MOE_INPUT_JITTER_EPS]
                       [--moe-per-layer-logging] [--moe-token-dispatcher-type {allgather,alltoall,flex}]
                       [--moe-enable-deepep] [--moe-deepep-num-sms MOE_DEEPEP_NUM_SMS] [--moe-permute-fusion]
                       [--moe-expert-capacity-factor MOE_EXPERT_CAPACITY_FACTOR] [--moe-pad-expert-input-to-capacity]
                       [--moe-token-drop-policy {probs,position}] [--moe-apply-probs-on-input]
                       [--overlap-moe-expert-parallel-comm] [--delay-wgrad-compute]
                       [--moe-upcycling-granularity MOE_UPCYCLING_GRANULARITY] [--q-lora-rank Q_LORA_RANK]
                       [--kv-lora-rank KV_LORA_RANK] [--qk-head-dim QK_HEAD_DIM]
                       [--qk-pos-emb-head-dim QK_POS_EMB_HEAD_DIM] [--v-head-dim V_HEAD_DIM]
                       [--rotary-scaling-factor ROTARY_SCALING_FACTOR] [--mscale MSCALE]
                       [--mscale-all-dim MSCALE_ALL_DIM] [--cache-mla-latents]
                       [--heterogeneous-layers-config-path HETEROGENEOUS_LAYERS_CONFIG_PATH]
                       [--heterogeneous-layers-config-encoded-json HETEROGENEOUS_LAYERS_CONFIG_ENCODED_JSON]
                       [--log-params-norm] [--log-num-zeros-in-grad] [--log-throughput] [--log-progress]
                       [--timing-log-level {0,1,2}] [--log-energy] [--no-barrier-with-level-1-timing]
                       [--timing-log-option {max,minmax,all}] [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]
                       [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE] [--log-timers-to-tensorboard]
                       [--no-log-loss-scale-to-tensorboard] [--log-validation-ppl-to-tensorboard]
                       [--log-memory-to-tensorboard] [--log-world-size-to-tensorboard] [--wandb-project WANDB_PROJECT]
                       [--wandb-entity WANDB_ENTITY] [--wandb-exp-name WANDB_EXP_NAME]
                       [--wandb-save-dir WANDB_SAVE_DIR] [--logging-level LOGGING_LEVEL] [--log-straggler]
                       [--disable-straggler-on-startup] [--straggler-ctrlr-port STRAGGLER_CTRLR_PORT]
                       [--straggler-minmax-count STRAGGLER_MINMAX_COUNT] [--run-workload-inspector-server]
                       [--inference-batch-times-seqlen-threshold INFERENCE_BATCH_TIMES_SEQLEN_THRESHOLD]
                       [--max-tokens-to-oom MAX_TOKENS_TO_OOM] [--output-bert-embeddings]
                       [--bert-embedder-type {megatron,huggingface}] [--flash-decode] [--enable-cuda-graph]
                       [--cuda-graph-warmup-steps CUDA_GRAPH_WARMUP_STEPS] [--external-cuda-graph]
                       [--cuda-graph-scope {full,attn,full_iteration}]
                       [--inference-max-requests INFERENCE_MAX_BATCH_SIZE]
                       [--inference-max-seq-length INFERENCE_MAX_SEQ_LENGTH]
                       [--inference-max-batch-size INFERENCE_MAX_BATCH_SIZE] [--inference-dynamic-batching]
                       [--inference-dynamic-batching-buffer-size-gb INFERENCE_DYNAMIC_BATCHING_BUFFER_SIZE_GB]
                       [--inference-dynamic-batching-chunk-size INFERENCE_DYNAMIC_BATCHING_CHUNK_SIZE]
                       [--inference-dynamic-batching-buffer-guaranteed-fraction INFERENCE_DYNAMIC_BATCHING_BUFFER_GUARANTEED_FRACTION]
                       [--inference-dynamic-batching-buffer-overflow-factor INFERENCE_DYNAMIC_BATCHING_BUFFER_OVERFLOW_FACTOR]
                       [--inference-dynamic-batching-max-requests-override INFERENCE_DYNAMIC_BATCHING_MAX_REQUESTS_OVERRIDE]
                       [--inference-dynamic-batching-max-tokens-override INFERENCE_DYNAMIC_BATCHING_MAX_TOKENS_OVERRIDE]
                       [--inference-dynamic-batching-num-cuda-graphs INFERENCE_DYNAMIC_BATCHING_NUM_CUDA_GRAPHS]
                       [--inference-dynamic-batching-track-paused-request-events]
                       [--inference-dynamic-batching-unified-memory-level {0,1}]
                       [--symmetric-ar-type {two_shot,one_shot,multimem_all_reduce,None}]
                       [--nccl-all-reduce-for-prefill] [--mlp-chunks-for-prefill MLP_CHUNKS_FOR_PREFILL]
                       [--initialize-socket-comms] [--disable-chunked-prefill] [--fp8-format {e4m3,hybrid}]
                       [--fp8-recipe {tensorwise,delayed,mxfp8,blockwise}] [--fp8-margin FP8_MARGIN]
                       [--fp8-interval FP8_INTERVAL] [--fp8-amax-history-len FP8_AMAX_HISTORY_LEN]
                       [--fp8-amax-compute-algo {most_recent,max}] [--no-fp8-wgrad]
                       [--transformer-impl {local,transformer_engine}] [--fp8-param-gather] [--first-last-layers-bf16]
                       [--num-layers-at-start-in-bf16 NUM_LAYERS_AT_START_IN_BF16]
                       [--num-layers-at-end-in-bf16 NUM_LAYERS_AT_END_IN_BF16] [--fp4-format {e2m1}]
                       [--fp4-recipe {nvfp4}] [--fp4-param-gather] [--te-rng-tracker] [--inference-rng-tracker]
                       [--retro-project-dir RETRO_PROJECT_DIR] [--retro-add-retriever]
                       [--retro-cyclic-train-iters RETRO_CYCLIC_TRAIN_ITERS]
                       [--retro-encoder-layers RETRO_ENCODER_LAYERS]
                       [--retro-encoder-hidden-dropout RETRO_ENCODER_HIDDEN_DROPOUT]
                       [--retro-encoder-attention-dropout RETRO_ENCODER_ATTENTION_DROPOUT]
                       [--retro-num-neighbors RETRO_NUM_NEIGHBORS]
                       [--retro-num-retrieved-chunks RETRO_NUM_RETRIEVED_CHUNKS]
                       [--retro-attention-gate RETRO_ATTENTION_GATE] [--retro-no-verify-neighbor-count]
                       [--enable-experimental] [--spec [SPEC ...]] [--hybrid-attention-ratio HYBRID_ATTENTION_RATIO]
                       [--hybrid-mlp-ratio HYBRID_MLP_RATIO] [--hybrid-override-pattern HYBRID_OVERRIDE_PATTERN]
                       [--mamba-state-dim MAMBA_STATE_DIM] [--mamba-head-dim MAMBA_HEAD_DIM]
                       [--mamba-num-groups MAMBA_NUM_GROUPS] [--mamba-num-heads MAMBA_NUM_HEADS] [--is-hybrid-model]
                       [--disable-mamba-mem-eff-path] [--yaml-cfg YAML_CFG] [--use-precision-aware-optimizer]
                       [--main-grads-dtype {fp32,bf16}] [--main-params-dtype {fp32,fp16}]
                       [--exp-avg-dtype {fp32,fp16,bf16,fp8}] [--exp-avg-sq-dtype {fp32,fp16,bf16,fp8}]
                       [--no-one-logger] [--one-logger-project ONE_LOGGER_PROJECT]
                       [--one-logger-run-name ONE_LOGGER_RUN_NAME] [--one-logger-async]
                       [--app-tag-run-name APP_TAG_RUN_NAME] [--app-tag-run-version APP_TAG_RUN_VERSION]
                       [--inprocess-restart] [--inprocess-max-iterations INPROCESS_MAX_ITERATIONS]
                       [--inprocess-monitor-thread-interval INPROCESS_MONITOR_THREAD_INTERVAL]
                       [--inprocess-monitor-process-interval INPROCESS_MONITOR_PROCESS_INTERVAL]
                       [--inprocess-progress-watchdog-interval INPROCESS_PROGRESS_WATCHDOG_INTERVAL]
                       [--inprocess-heartbeat-interval INPROCESS_HEARTBEAT_INTERVAL]
                       [--inprocess-soft-timeout INPROCESS_SOFT_TIMEOUT]
                       [--inprocess-hard-timeout INPROCESS_HARD_TIMEOUT]
                       [--inprocess-heartbeat-timeout INPROCESS_HEARTBEAT_TIMEOUT]
                       [--inprocess-barrier-timeout INPROCESS_BARRIER_TIMEOUT]
                       [--inprocess-completion-timeout INPROCESS_COMPLETION_TIMEOUT]
                       [--inprocess-last-call-wait INPROCESS_LAST_CALL_WAIT]
                       [--inprocess-termination-grace-time INPROCESS_TERMINATION_GRACE_TIME]
                       [--inprocess-granularity {node,rank}]
                       [--inprocess-active-world-size INPROCESS_ACTIVE_WORLD_SIZE] [--inprocess-empty-cuda-cache]
                       [--enable-ft-package] [--calc-ft-timeouts] [--config-logger-dir CONFIG_LOGGER_DIR]
                       [--error-injection-rate ERROR_INJECTION_RATE]
                       [--error-injection-type {correct_result,transient_error,persistent_error}]
                       [--rerun-mode {disabled,validate_results,report_stats}] [--disable-msc]
                       [--kitchen-config-file KITCHEN_CONFIG_FILE | --kitchen-recipe-number KITCHEN_RECIPE_NUMBER]
                       [--sft] [--sft-tokenizer-prompt-format SFT_TOKENIZER_PROMPT_FORMAT]
                       [--export-model-type {GPTModel,MambaModel}] [--export-legacy-megatron]
                       [--export-te-mcore-model] [--export-force-local-attention] [--export-kv-cache-quant]
                       [--export-real-quant-cfg {fp8_real_quant,fp8_blockwise_real_quant,None}]
                       [--export-quant-cfg {int8_sq,fp8,fp8_real_quant,fp8_blockwise,fp8_blockwise_real_quant,fp8_blockwise_32,int4_awq,w4a8_awq,nvfp4,None}]
                       [--export-kd-cfg EXPORT_KD_CFG] [--teacher-model-config TEACHER_MODEL_CONFIG]
                       [--export-kd-teacher-load EXPORT_KD_TEACHER_LOAD]
                       [--export-kd-teacher-ckpt-format {torch,torch_dist,zarr,torch_dcp}]
                       [--finetune-hf-dataset FINETUNE_HF_DATASET] [--finetune-data-split FINETUNE_DATA_SPLIT]
                       [--export-qk-l2-norm] [--export-moe-apply-probs-on-input] [--export-offline-model]
pretrain_gpt.py: error: unrecognized arguments: --mock_data
[2025-10-10 09:27:41,684] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 86) of binary: /opt/conda/bin/python
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.2.2', 'console_scripts', 'torchrun')())
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-10_09:27:41
  host      : server2
  rank      : 1 (local_rank: 0)
  exitcode  : 2 (pid: 86)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html